{
 "cells": [
  {
   "cell_type": "code",
   "id": "87d5286ddccf165",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T14:49:44.505608Z",
     "start_time": "2024-08-09T14:49:40.069580Z"
    }
   },
   "source": [
    "from llama3 import Llama\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import json\n",
    "from llama3.model import ModelArgs, Transformer\n",
    "from llama3.tokenizer import ChatFormat, Dialog, Message, Tokenizer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, GenerationConfig, TrainingArguments\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training, PeftModel, PeftConfig\n",
    "from trl import SFTTrainer\n",
    "from datasets import load_dataset, Dataset, Features, ClassLabel, Value"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "475f1a30ad5e6edc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T14:44:57.665269Z",
     "start_time": "2024-08-09T14:44:57.651268Z"
    }
   },
   "source": [
    "ckpt_dir = \"F:\\AugustRoboticsLLM\\Meta-Llama-3-8B-Instruct\"\n",
    "tokenizer_path = \"F:\\AugustRoboticsLLM\\Meta-Llama-3-8B-Instruct\"\n",
    "output_dir = \"F:\\AugustRoboticsLLM\\LoRAAdapter\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "peft_config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\",\n",
    "    \"up_proj\",\n",
    "    \"o_proj\",\n",
    "    \"k_proj\",\n",
    "    \"down_proj\",\n",
    "    \"gate_proj\",\n",
    "    \"v_proj\"],\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "29050385135d4d03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T14:44:57.957229Z",
     "start_time": "2024-08-09T14:44:57.666268Z"
    }
   },
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path, trust_remote_code=True, add_bos_token=False)\n",
    "tokenizer.padding_side = \"right\"\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "d962c406b7c6bbd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T14:31:03.290369Z",
     "start_time": "2024-08-09T14:31:01.786905Z"
    }
   },
   "source": [
    "class_names = [\"Symptom\", \"Solution1\", \"Solution2\", \"Solution3\", \"Solution4\", \"Solution5\", \"Solution6\", \"Solution7\"]\n",
    "features = Features({name: Value('string') for name in class_names})\n",
    "QandA_dataset = load_dataset(\"csv\", data_dir=\"F:\\AugustRoboticsLLM\\dataset\", sep=',', quoting=1, quotechar=r'\"', doublequote=True, features=features)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "366cf3931a952e28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T14:31:07.539728Z",
     "start_time": "2024-08-09T14:31:07.279448Z"
    }
   },
   "source": [
    "def prepare_dataset(dataset, tokenizer=tokenizer):\n",
    "    # prompting eng: https://github.com/meta-llama/llama-recipes/blob/main/recipes/quickstart/Prompt_Engineering_with_Llama_3.ipynb\n",
    "    # print(dataset)\n",
    "    solutions = []\n",
    "    for col in ['Solution1', 'Solution2', 'Solution3', 'Solution4', 'Solution5', 'Solution6', 'Solution7']:\n",
    "        if dataset[col] != None:\n",
    "            # print(dataset[col])\n",
    "            solutions.append(dataset[col])\n",
    "    \n",
    "    str_solutions = \"\"\n",
    "    for _idx, solution in enumerate(solutions):\n",
    "        str_solutions += solution + \". \"\n",
    "    dialogs = [\n",
    "        [{\"role\": \"system\", \"content\": \"Your role is an on-site robotics operation engineer who gives technical and practical advice to client who use Lionel robot to draw lines on the ground.\\n\"\n",
    "                                       \"You belong to August Robotics Ltd. Please do not answer any question not relate to our business, you can simply refuse it by saying no.\\n\"\n",
    "                                       \"Let's think through this carefully, step by step.\\n\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{dataset['Symptom']}\"},\n",
    "    {\"role\": \"assistant\", \"content\": f\"{str_solutions}\"\n",
    "                                          }],\n",
    "    ]\n",
    "    # print(type(tokenizer.apply_chat_template(dialogs, tokenize=False)[0]))\n",
    "    return {\"formattedchat\": tokenizer.apply_chat_template(dialogs, tokenize=False)[0]}\n",
    "\n",
    "QandA_dataset = QandA_dataset.map(prepare_dataset, remove_columns=('Symptom', 'Solution1', 'Solution2', 'Solution3', 'Solution4', 'Solution5', 'Solution6', 'Solution7'))\n",
    "# QandA_dataset = QandA_dataset.train_test_split(test_size=0.1)\n",
    "QandA_dataset"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/44 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6bb2042765254f56ba65c4d7362fe49a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['formattedchat'],\n",
       "        num_rows: 44\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T14:31:24.664086Z",
     "start_time": "2024-08-09T14:31:24.647086Z"
    }
   },
   "cell_type": "code",
   "source": "print(QandA_dataset[\"train\"][\"formattedchat\"][0])",
   "id": "af1efc90f8197165",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Your role is an on-site robotics operation engineer who gives technical and practical advice to client who use Lionel robot to draw lines on the ground.\n",
      "You belong to August Robotics Ltd. Please do not answer any question not relate to our business, you can simply refuse it by saying no.\n",
      "Let's think through this carefully, step by step.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Nothing is displayed when a map is viewed<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Refresh the webpage on the tablet, and navigate to the homepage (192.168.59.99). Ensure that the map has not been archived. If possible, hide the information layer using the show/hide tool. On the client portal (https://portal.augustrobotics.com/) ensure that the correct units were chosen when uploading the map (m / mm / inch).<|eot_id|>\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "ee66f190f1ffd10c",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "text_dataset = load_dataset(\"text\", data_dir=\"F:\\AugustRoboticsLLM\\/text_dataset\")\n",
    "print(text_dataset)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4d01f585c62fb030",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T14:32:21.595301Z",
     "start_time": "2024-08-09T14:31:48.320346Z"
    }
   },
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(ckpt_dir, quantization_config=bnb_config, device_map=\"auto\")\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model = prepare_model_for_kbit_training(model)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "94a654e1f66c49ebbcfa5b94d74165b3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24cb006812048a5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T07:58:48.584093Z",
     "start_time": "2024-08-04T07:58:26.498481Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3be778417a6140caa6f1706d6c15edcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device device because they were offloaded to the disk and cpu.\n"
     ]
    }
   ],
   "source": [
    "del model\n",
    "model = AutoModelForCausalLM.from_pretrained(ckpt_dir, \n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.float16, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "469c74210bd06e14",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-08-09T14:33:32.470795Z"
    }
   },
   "source": [
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=1,\n",
    "    num_train_epochs=5,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=100,\n",
    "    logging_steps=5,\n",
    "    learning_rate=0.0002,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    dataloader_num_workers=0\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=text_dataset[\"train\"],\n",
    "    peft_config=peft_config,\n",
    "    # dataset_text_field=\"formattedchat\",\n",
    "    dataset_text_field=\"text\",\n",
    "    dataset_batch_size=1,\n",
    "    max_seq_length=1024,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing=True,\n",
    "    \n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.model.save_pretrained(output_dir)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "81fdd53938634e51aabb1c4ff9d1a7a6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='101' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [101/105 06:48 < 00:16, 0.24 it/s, Epoch 4.76/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.417200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.168800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.832200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.649800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.388900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.313500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>2.436800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.216900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.918200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.012900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.837600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.720300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>1.576300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.320200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.378000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.363300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>1.239500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.223100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>1.142200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f66b1625f6b5f554",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T15:24:56.214901Z",
     "start_time": "2024-08-08T15:24:30.738803Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6319e2206b274de8abfdc287a1c75b30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Can't find 'adapter_config.json' at 'F:\\AugustRoboticsLLM\\LoRAAdapter'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mHFValidationError\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\peft\\config.py:205\u001B[0m, in \u001B[0;36mPeftConfigMixin._get_peft_type\u001B[1;34m(cls, model_id, **hf_hub_download_kwargs)\u001B[0m\n\u001B[0;32m    204\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 205\u001B[0m     config_file \u001B[38;5;241m=\u001B[39m hf_hub_download(\n\u001B[0;32m    206\u001B[0m         model_id,\n\u001B[0;32m    207\u001B[0m         CONFIG_NAME,\n\u001B[0;32m    208\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mhf_hub_download_kwargs,\n\u001B[0;32m    209\u001B[0m     )\n\u001B[0;32m    210\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:101\u001B[0m, in \u001B[0;36m_deprecate_arguments.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    100\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(message, \u001B[38;5;167;01mFutureWarning\u001B[39;00m)\n\u001B[1;32m--> 101\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:106\u001B[0m, in \u001B[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    105\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m arg_name \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrepo_id\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfrom_id\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mto_id\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[1;32m--> 106\u001B[0m     \u001B[43mvalidate_repo_id\u001B[49m\u001B[43m(\u001B[49m\u001B[43marg_value\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    108\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m arg_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtoken\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m arg_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:160\u001B[0m, in \u001B[0;36mvalidate_repo_id\u001B[1;34m(repo_id)\u001B[0m\n\u001B[0;32m    159\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m REPO_ID_REGEX\u001B[38;5;241m.\u001B[39mmatch(repo_id):\n\u001B[1;32m--> 160\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m HFValidationError(\n\u001B[0;32m    161\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRepo id must use alphanumeric chars or \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m-\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m--\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m and \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m..\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m are\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    162\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m forbidden, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m-\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m and \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m cannot start or end the name, max length is 96:\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    163\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrepo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    164\u001B[0m     )\n\u001B[0;32m    166\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m--\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m repo_id \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m..\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m repo_id:\n",
      "\u001B[1;31mHFValidationError\u001B[0m: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: 'F:\\AugustRoboticsLLM\\LoRAAdapter'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 8\u001B[0m\n\u001B[0;32m      1\u001B[0m base_model \u001B[38;5;241m=\u001B[39m AutoModelForCausalLM\u001B[38;5;241m.\u001B[39mfrom_pretrained(\n\u001B[0;32m      2\u001B[0m     ckpt_dir,\n\u001B[0;32m      3\u001B[0m     low_cpu_mem_usage\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m      6\u001B[0m     offload_buffers\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m      7\u001B[0m )\n\u001B[1;32m----> 8\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mPeftModel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mF:\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mAugustRoboticsLLM\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mLoRAAdapter\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcpu\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m model \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mmerge_and_unload()\n\u001B[0;32m     10\u001B[0m model\u001B[38;5;241m.\u001B[39msave_pretrained(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mF:\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mAugustRoboticsLLM\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mARLLM\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\peft\\peft_model.py:453\u001B[0m, in \u001B[0;36mPeftModel.from_pretrained\u001B[1;34m(cls, model, model_id, adapter_name, is_trainable, config, autocast_adapter_dtype, ephemeral_gpu_offload, **kwargs)\u001B[0m\n\u001B[0;32m    450\u001B[0m \u001B[38;5;66;03m# load the config\u001B[39;00m\n\u001B[0;32m    451\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m config \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    452\u001B[0m     config \u001B[38;5;241m=\u001B[39m PEFT_TYPE_TO_CONFIG_MAPPING[\n\u001B[1;32m--> 453\u001B[0m         \u001B[43mPeftConfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_peft_type\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    454\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmodel_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    455\u001B[0m \u001B[43m            \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msubfolder\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    456\u001B[0m \u001B[43m            \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrevision\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    457\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcache_dir\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    458\u001B[0m \u001B[43m            \u001B[49m\u001B[43muse_auth_token\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muse_auth_token\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    459\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtoken\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    460\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    461\u001B[0m     ]\u001B[38;5;241m.\u001B[39mfrom_pretrained(model_id, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    462\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(config, PeftConfig):\n\u001B[0;32m    463\u001B[0m     config\u001B[38;5;241m.\u001B[39minference_mode \u001B[38;5;241m=\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m is_trainable\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\peft\\config.py:211\u001B[0m, in \u001B[0;36mPeftConfigMixin._get_peft_type\u001B[1;34m(cls, model_id, **hf_hub_download_kwargs)\u001B[0m\n\u001B[0;32m    205\u001B[0m         config_file \u001B[38;5;241m=\u001B[39m hf_hub_download(\n\u001B[0;32m    206\u001B[0m             model_id,\n\u001B[0;32m    207\u001B[0m             CONFIG_NAME,\n\u001B[0;32m    208\u001B[0m             \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mhf_hub_download_kwargs,\n\u001B[0;32m    209\u001B[0m         )\n\u001B[0;32m    210\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m--> 211\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCan\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt find \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mCONFIG_NAME\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m at \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    213\u001B[0m loaded_attributes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mfrom_json_file(config_file)\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loaded_attributes[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpeft_type\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "\u001B[1;31mValueError\u001B[0m: Can't find 'adapter_config.json' at 'F:\\AugustRoboticsLLM\\LoRAAdapter'"
     ]
    }
   ],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    ckpt_dir,\n",
    "    low_cpu_mem_usage=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"cpu\",\n",
    "    offload_buffers=False,\n",
    ")\n",
    "model = PeftModel.from_pretrained(base_model, \"F:\\AugustRoboticsLLM\\LoRAAdapter\", device_map=\"cpu\")\n",
    "model = model.merge_and_unload()\n",
    "model.save_pretrained(\"F:\\AugustRoboticsLLM\\ARLLM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c170d830fda25b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[128000,     40,   4510,    279,   7438,    315,   2324,    374, 128009,\n",
      "         128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
      "         128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
      "         128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
      "         128009, 128009, 128009, 128009],\n",
      "        [128000,  61346,   2231,     11,    279,  10334,    315,   1375,  44515,\n",
      "           5415,    430,    220, 128009, 128009, 128009, 128009, 128009, 128009,\n",
      "         128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
      "         128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
      "         128009, 128009, 128009, 128009],\n",
      "        [128000,     32,  10015,   1984,  40588,  15853,    279,   2128,    389,\n",
      "            279,   7195,   1473,    286,  21694,   5127,   3638,    286,    358,\n",
      "           1120,    220, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
      "         128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
      "         128009, 128009, 128009, 128009],\n",
      "        [128000,  28573,   6498,    311,   8753,   1473,    286,   9581,  14479,\n",
      "            466,    591,    326,    412,    265,    409,   4809,    198,    286,\n",
      "          83804,  94932,    591,  11540,    383,   3273,  58866,   8047,    198,\n",
      "            286,  72779,  41389,   5763,    591,  41389,   5763,  12077,  34927,\n",
      "            198,    286,  17604,    591]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "generation_config = GenerationConfig.from_pretrained(ckpt_dir)\n",
    "generation_config.max_new_tokens=150\n",
    "generation_config.repetition_penalty = 1.1\n",
    "prompts = [\n",
    "        # For these prompts, the expected answer is the natural continuation of the prompt\n",
    "        \"The robot Lionel is designed to\",\n",
    "    ]\n",
    "model_inputs = tokenizer(prompts, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "output = model.generate(**model_inputs, generation_config=generation_config)\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "id": "af1947c83fc72c0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T14:11:00.958180Z",
     "start_time": "2024-08-09T14:10:32.193994Z"
    }
   },
   "source": [
    "generation_config = GenerationConfig.from_pretrained(ckpt_dir)\n",
    "generation_config.max_new_tokens=150\n",
    "generation_config.repetition_penalty = 1.1\n",
    "model_inputs = tokenizer(tokenizer.apply_chat_template([{\"role\": \"system\", \"content\": \"Your role is an on-site robotics operation engineer who gives technical and practical advice to client who use Lionel robot to draw lines on the ground.\\n\"\n",
    "                                       \"You belong to August Robotics Ltd. Please do not answer any question not relate to our business, you can simply refuse it by saying no.\\n\"\n",
    "                                       \"Let's think through this carefully, step by step.\\n\"},{\"role\": \"user\", \"content\": \"What is Lionel and GS?\"}], tokenize=False), return_tensors=\"pt\").to(\"cuda\")\n",
    "print(model_inputs)\n",
    "output = model.generate(**model_inputs, generation_config=generation_config)\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=False))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[128000, 128000, 128006,   9125, 128007,    271,   7927,   3560,    374,\n",
      "            459,    389,  29654,  74706,   5784,  24490,    889,   6835,  11156,\n",
      "            323,  15325,   9650,    311,   3016,    889,   1005,  84224,  12585,\n",
      "            311,   4128,   5238,    389,    279,   5015,    627,   2675,   9352,\n",
      "            311,   6287,  77564,  12604,     13,   5321,    656,    539,   4320,\n",
      "            904,   3488,    539,  29243,    311,   1057,   2626,     11,    499,\n",
      "            649,   5042,  26122,    433,    555,   5605,    912,    627,  10267,\n",
      "            596,   1781,   1555,    420,  15884,     11,   3094,    555,   3094,\n",
      "             13, 128009, 128006,    882, 128007,    271,   3923,    374,  84224,\n",
      "            323,  36370,     30, 128009]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n",
      "<|begin_of_text|><|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Your role is an on-site robotics operation engineer who gives technical and practical advice to client who use Lionel robot to draw lines on the ground.\n",
      "You belong to August Robotics Ltd. Please do not answer any question not relate to our business, you can simply refuse it by saying no.\n",
      "Let's think through this carefully, step by step.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "What is Lionel and GS?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Here are the possible answers provided by me: \n",
      "\t0: GS is a Guiding Station of Lionel - a device that emits a laser beam to guide Lionel as it marks a job\n",
      "\t1: GS is the abbreviation for \"Guiding Station\"\n",
      "\t2: None of the above\n",
      "\t3: GS is an acronym that stands for various things depending on the context in which it is used (e.g. \"GS\" could stand for \"Guiding Station\", \"Gantry Stop\", etc.)<|eot_id|>\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "e023b9f7ecd8ed3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T14:20:54.046309Z",
     "start_time": "2024-08-09T14:20:53.918279Z"
    }
   },
   "source": [
    "import gc\n",
    "del model\n",
    "gc.collect()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f0e59dad73617d9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T15:40:06.171509Z",
     "start_time": "2024-08-06T15:40:06.140995Z"
    }
   },
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f966435e59825e8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T15:40:10.183658Z",
     "start_time": "2024-08-06T15:40:10.064149Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "id": "2dfcd88fcc728a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T14:21:09.340324Z",
     "start_time": "2024-08-09T14:21:09.306319Z"
    }
   },
   "source": "model.unload()",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241m.\u001B[39munload()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4b545d576077b89d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
