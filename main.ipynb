{
 "cells": [
  {
   "cell_type": "code",
   "id": "87d5286ddccf165",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T14:43:14.801665Z",
     "start_time": "2024-08-10T14:43:09.537819Z"
    }
   },
   "source": [
    "from llama3 import Llama\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import json\n",
    "from llama3.model import ModelArgs, Transformer\n",
    "from llama3.tokenizer import ChatFormat, Dialog, Message, Tokenizer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, GenerationConfig, TrainingArguments\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training, PeftModel, PeftConfig\n",
    "from trl import SFTTrainer\n",
    "from datasets import load_dataset, Dataset, Features, ClassLabel, Value"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "475f1a30ad5e6edc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T14:43:14.813673Z",
     "start_time": "2024-08-10T14:43:14.801665Z"
    }
   },
   "source": [
    "ckpt_dir = \"F:\\AugustRoboticsLLM\\Meta-Llama-3-8B-Instruct\"\n",
    "tokenizer_path = \"F:\\AugustRoboticsLLM\\Meta-Llama-3-8B-Instruct\"\n",
    "output_dir = \"F:\\AugustRoboticsLLM\\LoRAAdapter\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "peft_config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\",\n",
    "    \"up_proj\",\n",
    "    \"o_proj\",\n",
    "    \"k_proj\",\n",
    "    \"down_proj\",\n",
    "    \"gate_proj\",\n",
    "    \"v_proj\"],\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "29050385135d4d03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T14:43:15.101813Z",
     "start_time": "2024-08-10T14:43:14.813673Z"
    }
   },
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path, trust_remote_code=True, add_bos_token=False)\n",
    "tokenizer.padding_side = \"right\"\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "d962c406b7c6bbd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T12:01:20.275587Z",
     "start_time": "2024-08-10T12:01:19.250407Z"
    }
   },
   "source": [
    "class_names = [\"Symptom\", \"Solution\"]\n",
    "features = Features({name: Value('string') for name in class_names})\n",
    "QandA_dataset = load_dataset(\"csv\", data_dir=\"F:\\AugustRoboticsLLM\\dataset\", sep=',', quoting=1, quotechar=r'\"', doublequote=True, features=features)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "366cf3931a952e28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T12:01:20.442403Z",
     "start_time": "2024-08-10T12:01:20.275587Z"
    }
   },
   "source": [
    "def prepare_dataset(dataset, tokenizer=tokenizer):\n",
    "    # prompting eng: https://github.com/meta-llama/llama-recipes/blob/main/recipes/quickstart/Prompt_Engineering_with_Llama_3.ipynb\n",
    "    dialogs = [\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": \"Your role is an on-site robotics operation engineer who gives technical and practical advice to client who use Lionel robot to draw marks on the exhibition.\\n\"\n",
    "                                       \"You belong to August Robotics Ltd. Please do not answer any question not relate to our business, you can simply refuse it by saying no.\\n\"\n",
    "                                       \"Let's think through this carefully, step by step.\\n\"},\n",
    "            {\"role\": \"user\", \"content\": f\"{dataset['Symptom']}\"},\n",
    "            {\"role\": \"assistant\", \"content\": f\"{dataset['Solution']}\"}\n",
    "        ],\n",
    "    ]\n",
    "    # print(type(tokenizer.apply_chat_template(dialogs, tokenize=False)[0]))\n",
    "    return {\"formattedchat\": tokenizer.apply_chat_template(dialogs, tokenize=False)[0]}\n",
    "\n",
    "QandA_dataset = QandA_dataset.map(prepare_dataset, remove_columns=('Symptom', 'Solution'))\n",
    "# QandA_dataset = QandA_dataset.train_test_split(test_size=0.1)\n",
    "QandA_dataset"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['formattedchat'],\n",
       "        num_rows: 32\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T08:02:02.829415Z",
     "start_time": "2024-08-10T08:02:02.819416Z"
    }
   },
   "cell_type": "code",
   "source": "print(QandA_dataset[\"train\"][\"formattedchat\"][0])",
   "id": "af1efc90f8197165",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Your role is an on-site robotics operation engineer who gives technical and practical advice to client who use Lionel robot to draw lines on the ground.\n",
      "You belong to August Robotics Ltd. Please do not answer any question not relate to our business, you can simply refuse it by saying no.\n",
      "Let's think through this carefully, step by step.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Nothing is displayed when a map is viewed on the tablet<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Start by refreshing the webpage on your tablet and navigate back to the map. Confirm that the map has not been archived. If the problem persists, access the client portal at https://portal.augustrobotics.com and verify that the map is still active.<|eot_id|>\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "ee66f190f1ffd10c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T12:01:21.401194Z",
     "start_time": "2024-08-10T12:01:20.443403Z"
    }
   },
   "source": [
    "text_dataset = load_dataset(\"text\", data_dir=\"F:\\AugustRoboticsLLM\\/text_dataset\")\n",
    "print(text_dataset)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 517\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "4d01f585c62fb030",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T14:43:53.752109Z",
     "start_time": "2024-08-10T14:43:43.436892Z"
    }
   },
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"F:\\AugustRoboticsLLM\\ARLLM\", quantization_config=bnb_config, device_map=\"auto\")\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "# model = prepare_model_for_kbit_training(model)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "63e28b179e4c4350bb38e26f68c75263"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Embedding(128256, 4096)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24cb006812048a5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T07:58:48.584093Z",
     "start_time": "2024-08-04T07:58:26.498481Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3be778417a6140caa6f1706d6c15edcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device device because they were offloaded to the disk and cpu.\n"
     ]
    }
   ],
   "source": [
    "del model\n",
    "model = AutoModelForCausalLM.from_pretrained(ckpt_dir, \n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.float16, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "469c74210bd06e14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T12:31:59.577547Z",
     "start_time": "2024-08-10T12:30:57.016858Z"
    }
   },
   "source": [
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=1,\n",
    "    num_train_epochs=2,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=200,\n",
    "    logging_steps=50,\n",
    "    learning_rate=0.0004,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=False,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    dataloader_num_workers=0\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=QandA_dataset[\"train\"],\n",
    "    # train_dataset=text_dataset[\"train\"],\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"formattedchat\",\n",
    "    # dataset_text_field=\"text\",\n",
    "    dataset_batch_size=1,\n",
    "    max_seq_length=512,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing=False,\n",
    "    \n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.model.save_pretrained(output_dir)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\myper\\.conda\\envs\\ml\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\myper\\.conda\\envs\\ml\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:59, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.241100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "f66b1625f6b5f554",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T14:40:04.114966Z",
     "start_time": "2024-08-10T14:38:58.717079Z"
    }
   },
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    ckpt_dir,\n",
    "    low_cpu_mem_usage=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"cpu\",\n",
    "    offload_buffers=False,\n",
    ")\n",
    "model = PeftModel.from_pretrained(base_model, \"F:\\AugustRoboticsLLM\\LoRAAdapter\", device_map=\"cpu\")\n",
    "model = model.merge_and_unload()\n",
    "model.save_pretrained(\"F:\\AugustRoboticsLLM\\ARLLM\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2ac8970986a8489ca41d01492e8736d7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "c170d830fda25b13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T11:12:57.002243Z",
     "start_time": "2024-08-10T11:12:17.308653Z"
    }
   },
   "source": [
    "generation_config = GenerationConfig.from_pretrained(ckpt_dir)\n",
    "generation_config.max_new_tokens=150\n",
    "generation_config.repetition_penalty = 1.1\n",
    "prompts = [\n",
    "        # For these prompts, the expected answer is the natural continuation of the prompt\n",
    "        \"The Guiding Station is designed for\",\n",
    "    ]\n",
    "model_inputs = tokenizer(prompts, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "output = model.generate(**model_inputs, generation_config=generation_config)\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=False))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "C:\\Users\\myper\\.conda\\envs\\ml\\lib\\site-packages\\transformers\\generation\\utils.py:1850: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\myper\\.conda\\envs\\ml\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\myper\\.conda\\envs\\ml\\lib\\site-packages\\torch\\utils\\checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>The Guiding Station is designed for Lionel to understand its position in the hall and adjust itself before each job. It consists of a physical beacon (LED light) that Lionel can see, and a camera that Lionel uses to determine its precise position relative to the beacon. The Guiding Station will be placed in a fixed position in the hall by August Robotics before the first day of the event, so that it knows exactly where it is in the hall. Once the Lionel robot is turned on, it will look for the Guiding Station and use its camera to determine its position relative to the beacon, and thereby calculate its own position in the hall. This step is called “self-leveling”. After self-leveling, Lionel’s laser will be precisely aligned with the reference points, allowing Lionel\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "af1947c83fc72c0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T14:44:26.405117Z",
     "start_time": "2024-08-10T14:44:12.052120Z"
    }
   },
   "source": [
    "generation_config = GenerationConfig.from_pretrained(ckpt_dir)\n",
    "generation_config.max_new_tokens=200\n",
    "generation_config.repetition_penalty = 1.1\n",
    "generation_config.temperature = 0.2\n",
    "generation_config.top_k = 20\n",
    "generation_config.top_p = 0.2\n",
    "model_inputs = tokenizer(tokenizer.apply_chat_template([\n",
    "    {\n",
    "    \"role\": \"system\", \"content\": \"Your role is an on-site robotics operation engineer who gives technical and practical advice to client who use Lionel robot to draw lines on the ground.\\n\"\n",
    "    \"You belong to August Robotics Ltd. Please do not answer any question not relate to our business, you can simply refuse it by saying no.\\n\"\n",
    "    \"Let's think through this carefully, step by step.\\n\"\n",
    "    \"Lionel is a four-wheeled robot that autonomously moves, localises and makes floor markings in exhibition halls. Lionel has Camera Beacon, Multiple Sensors, Mobile Base, Mesh Router, Spray Marking Mechanism \\n\"\n",
    "    \"Guiding Station is a stationary piece of equipment that helps the Lionel to get its location in the hall to spray marks accurately. It has a camera, a laser measurement unit, and a beacon (green and red LED lights) \\n\"\n",
    "    \"Map Server is a server like system which control and management all the devices (Lionel and GS) connected to it. It can be accessed by using the provided tablet with browser, i.e. webpage application \\n\"\n",
    "    \"Reference Beacon is a LED light with blue and green color device which is placed on the reference points in the hall during the set-up process to allow the Guiding Station to calculate its position \\n\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\", \"content\": \"How does the whole system work anyway?\"\n",
    "    }], tokenize=False), return_tensors=\"pt\").to(\"cuda\")\n",
    "print(model_inputs)\n",
    "output = model.generate(**model_inputs, generation_config=generation_config)\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=False))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[128000, 128000, 128006,   9125, 128007,    271,   7927,   3560,    374,\n",
      "            459,    389,  29654,  74706,   5784,  24490,    889,   6835,  11156,\n",
      "            323,  15325,   9650,    311,   3016,    889,   1005,  84224,  12585,\n",
      "            311,   4128,   5238,    389,    279,   5015,    627,   2675,   9352,\n",
      "            311,   6287,  77564,  12604,     13,   5321,    656,    539,   4320,\n",
      "            904,   3488,    539,  29243,    311,   1057,   2626,     11,    499,\n",
      "            649,   5042,  26122,    433,    555,   5605,    912,    627,  10267,\n",
      "            596,   1781,   1555,    420,  15884,     11,   3094,    555,   3094,\n",
      "            627,     43,    290,    301,    374,    264,   3116,   2695,    383,\n",
      "          41189,  12585,    430,  95103,   7162,  11031,     11,   2254,   5014,\n",
      "            323,   3727,   6558,  65172,    304,  28099,  52473,     13,  84224,\n",
      "            706,  14669,  59720,     11,  29911,  95520,     11,  13716,   5464,\n",
      "             11,  26179,  10777,     11,  61661,   4488,    287,  28901,   2191,\n",
      "            720,  17100,    287,  17040,    374,    264,  53735,   6710,    315,\n",
      "           7241,    430,   8779,    279,  84224,    311,    636,   1202,   3813,\n",
      "            304,    279,  14321,    311,  23749,  15785,  30357,     13,   1102,\n",
      "            706,    264,   6382,     11,    264,  21120,  19179,   5089,     11,\n",
      "            323,    264,  52402,    320,  13553,    323,   2579,  13414,  13001,\n",
      "              8,    720,   2276,   8588,    374,    264,   3622,   1093,   1887,\n",
      "            902,   2585,    323,   6373,    682,    279,   7766,    320,     43,\n",
      "            290,    301,    323,  36370,      8,   8599,    311,    433,     13,\n",
      "           1102,    649,    387,  25790,    555,   1701,    279,   3984,  21354,\n",
      "            449,   7074,     11,    602,   1770,     13,  45710,   3851,    720,\n",
      "           9032,  59720,    374,    264,  13414,   3177,    449,   6437,    323,\n",
      "           6307,   1933,   3756,    902,    374,   9277,    389,    279,   5905,\n",
      "           3585,    304,    279,  14321,   2391,    279,    743,   5352,   1920,\n",
      "            311,   2187,    279,  12433,    287,  17040,    311,  11294,   1202,\n",
      "           2361, 128009, 128006,    882, 128007,    271,   4438,   1587,    279,\n",
      "           4459,   1887,    990,  13971,     30, 128009]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "       device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\myper\\.conda\\envs\\ml\\lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:603: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Your role is an on-site robotics operation engineer who gives technical and practical advice to client who use Lionel robot to draw lines on the ground.\n",
      "You belong to August Robotics Ltd. Please do not answer any question not relate to our business, you can simply refuse it by saying no.\n",
      "Let's think through this carefully, step by step.\n",
      "Lionel is a four-wheeled robot that autonomously moves, localises and makes floor markings in exhibition halls. Lionel has Camera Beacon, Multiple Sensors, Mobile Base, Mesh Router, Spray Marking Mechanism \n",
      "Guiding Station is a stationary piece of equipment that helps the Lionel to get its location in the hall to spray marks accurately. It has a camera, a laser measurement unit, and a beacon (green and red LED lights) \n",
      "Map Server is a server like system which control and management all the devices (Lionel and GS) connected to it. It can be accessed by using the provided tablet with browser, i.e. webpage application \n",
      "Reference Beacon is a LED light with blue and green color device which is placed on the reference points in the hall during the set-up process to allow the Guiding Station to calculate its position<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "How does the whole system work anyway?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "The Map Server is the central hub for the entire system. It connects to the Guiding Station, Lionel, and other devices via WiFi or Ethernet cables. The Map Server uses the data from these devices to create a map of the exhibition hall, which is then used to guide Lionel as it draws marks on the ground. The Reference Beacons are used to help the Guiding Station determine its own location within the map. Finally, the Map Server communicates with the tablet to display the current state of the job, including the location of Lionel and the marks being drawn. If there are any errors or issues, the Map Server will alert the user through notifications on the tablet.<|eot_id|>\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T14:57:36.151190Z",
     "start_time": "2024-08-10T14:57:36.139177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# print(tokenizer.decode(model_inputs[\"input_ids\"][0], skip_special_tokens=True))\n",
    "print(tokenizer.decode(output[0][len(model_inputs[\"input_ids\"][0])+2:], skip_special_tokens=True).strip())\n"
   ],
   "id": "c89c67e3d3059037",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Map Server is the central hub for the entire system. It connects to the Guiding Station, Lionel, and other devices via WiFi or Ethernet cables. The Map Server uses the data from these devices to create a map of the exhibition hall, which is then used to guide Lionel as it draws marks on the ground. The Reference Beacons are used to help the Guiding Station determine its own location within the map. Finally, the Map Server communicates with the tablet to display the current state of the job, including the location of Lionel and the marks being drawn. If there are any errors or issues, the Map Server will alert the user through notifications on the tablet.\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T17:26:22.450702Z",
     "start_time": "2024-08-09T17:26:07.766332Z"
    }
   },
   "cell_type": "code",
   "source": "model = AutoModelForCausalLM.from_pretrained(\"F:\\AugustRoboticsLLM\\ARLLM\", quantization_config=bnb_config, device_map=\"auto\")",
   "id": "ce3389383511036e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8dea36d91c95474e86729f1cb0824dbd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "e023b9f7ecd8ed3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T14:38:25.412994Z",
     "start_time": "2024-08-10T14:38:25.296995Z"
    }
   },
   "source": [
    "import gc\n",
    "del model\n",
    "gc.collect()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "f0e59dad73617d9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T11:54:09.476811Z",
     "start_time": "2024-08-10T11:54:09.464810Z"
    }
   },
   "source": "del QandA_dataset",
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "f966435e59825e8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T14:38:27.318868Z",
     "start_time": "2024-08-10T14:38:27.206868Z"
    }
   },
   "source": [
    "gc.collect()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "2dfcd88fcc728a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T14:21:09.340324Z",
     "start_time": "2024-08-09T14:21:09.306319Z"
    }
   },
   "source": "model.unload()",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241m.\u001B[39munload()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4b545d576077b89d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
