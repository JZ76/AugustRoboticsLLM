{
 "cells": [
  {
   "cell_type": "code",
   "id": "87d5286ddccf165",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T07:39:19.912541Z",
     "start_time": "2024-08-10T07:39:08.211817Z"
    }
   },
   "source": [
    "from llama3 import Llama\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import json\n",
    "from llama3.model import ModelArgs, Transformer\n",
    "from llama3.tokenizer import ChatFormat, Dialog, Message, Tokenizer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, GenerationConfig, TrainingArguments\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training, PeftModel, PeftConfig\n",
    "from trl import SFTTrainer\n",
    "from datasets import load_dataset, Dataset, Features, ClassLabel, Value"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "475f1a30ad5e6edc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T07:39:19.928542Z",
     "start_time": "2024-08-10T07:39:19.913542Z"
    }
   },
   "source": [
    "ckpt_dir = \"F:\\AugustRoboticsLLM\\Meta-Llama-3-8B-Instruct\"\n",
    "tokenizer_path = \"F:\\AugustRoboticsLLM\\Meta-Llama-3-8B-Instruct\"\n",
    "output_dir = \"F:\\AugustRoboticsLLM\\LoRAAdapter\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "peft_config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\",\n",
    "    \"up_proj\",\n",
    "    \"o_proj\",\n",
    "    \"k_proj\",\n",
    "    \"down_proj\",\n",
    "    \"gate_proj\",\n",
    "    \"v_proj\"],\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "29050385135d4d03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T07:39:20.250791Z",
     "start_time": "2024-08-10T07:39:19.929541Z"
    }
   },
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path, trust_remote_code=True, add_bos_token=False)\n",
    "tokenizer.padding_side = \"right\"\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "d962c406b7c6bbd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T07:55:51.790822Z",
     "start_time": "2024-08-10T07:55:50.320640Z"
    }
   },
   "source": [
    "class_names = [\"Symptom\", \"Solution\"]\n",
    "features = Features({name: Value('string') for name in class_names})\n",
    "QandA_dataset = load_dataset(\"csv\", data_dir=\"F:\\AugustRoboticsLLM\\dataset\", sep=',', quoting=1, quotechar=r'\"', doublequote=True, features=features)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "50a5be390cff4c9ab702a88af0941d0b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\myper\\.conda\\envs\\ml\\lib\\site-packages\\datasets\\download\\streaming_download_manager.py:784: FutureWarning: The 'verbose' keyword in pd.read_csv is deprecated and will be removed in a future version.\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", download_config=download_config), **kwargs)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "366cf3931a952e28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T08:02:00.341875Z",
     "start_time": "2024-08-10T08:02:00.158855Z"
    }
   },
   "source": [
    "def prepare_dataset(dataset, tokenizer=tokenizer):\n",
    "    # prompting eng: https://github.com/meta-llama/llama-recipes/blob/main/recipes/quickstart/Prompt_Engineering_with_Llama_3.ipynb\n",
    "    dialogs = [\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": \"Your role is an on-site robotics operation engineer who gives technical and practical advice to client who use Lionel robot to draw marks on the exhibition.\\n\"\n",
    "                                       \"You belong to August Robotics Ltd. Please do not answer any question not relate to our business, you can simply refuse it by saying no.\\n\"\n",
    "                                       \"Let's think through this carefully, step by step.\\n\"},\n",
    "            {\"role\": \"user\", \"content\": f\"{dataset['Symptom']}\"},\n",
    "            {\"role\": \"assistant\", \"content\": f\"{dataset['Solution']}\"}\n",
    "        ],\n",
    "    ]\n",
    "    # print(type(tokenizer.apply_chat_template(dialogs, tokenize=False)[0]))\n",
    "    return {\"formattedchat\": tokenizer.apply_chat_template(dialogs, tokenize=False)[0]}\n",
    "\n",
    "QandA_dataset = QandA_dataset.map(prepare_dataset, remove_columns=('Symptom', 'Solution'))\n",
    "# QandA_dataset = QandA_dataset.train_test_split(test_size=0.1)\n",
    "QandA_dataset"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/32 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7c7235cb4f8a401e9e0af0e09713a922"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['formattedchat'],\n",
       "        num_rows: 32\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T08:02:02.829415Z",
     "start_time": "2024-08-10T08:02:02.819416Z"
    }
   },
   "cell_type": "code",
   "source": "print(QandA_dataset[\"train\"][\"formattedchat\"][0])",
   "id": "af1efc90f8197165",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Your role is an on-site robotics operation engineer who gives technical and practical advice to client who use Lionel robot to draw lines on the ground.\n",
      "You belong to August Robotics Ltd. Please do not answer any question not relate to our business, you can simply refuse it by saying no.\n",
      "Let's think through this carefully, step by step.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Nothing is displayed when a map is viewed on the tablet<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Start by refreshing the webpage on your tablet and navigate back to the map. Confirm that the map has not been archived. If the problem persists, access the client portal at https://portal.augustrobotics.com and verify that the map is still active.<|eot_id|>\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "ee66f190f1ffd10c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T07:39:26.741828Z",
     "start_time": "2024-08-10T07:39:25.456388Z"
    }
   },
   "source": [
    "text_dataset = load_dataset(\"text\", data_dir=\"F:\\AugustRoboticsLLM\\/text_dataset\")\n",
    "print(text_dataset)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "015f2be7c3ff484b89c246fd143c6cf2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 515\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "4d01f585c62fb030",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T07:40:24.205042Z",
     "start_time": "2024-08-10T07:39:58.622999Z"
    }
   },
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(ckpt_dir, quantization_config=bnb_config, device_map=\"auto\")\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model = prepare_model_for_kbit_training(model)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6fad58a413f44c1fb2f99a864609e33f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24cb006812048a5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T07:58:48.584093Z",
     "start_time": "2024-08-04T07:58:26.498481Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3be778417a6140caa6f1706d6c15edcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device device because they were offloaded to the disk and cpu.\n"
     ]
    }
   ],
   "source": [
    "del model\n",
    "model = AutoModelForCausalLM.from_pretrained(ckpt_dir, \n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.float16, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "469c74210bd06e14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T08:02:47.683055Z",
     "start_time": "2024-08-10T08:02:12.964822Z"
    }
   },
   "source": [
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=1,\n",
    "    num_train_epochs=1,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=200,\n",
    "    logging_steps=5,\n",
    "    learning_rate=0.0001,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=False,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    dataloader_num_workers=0\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=QandA_dataset[\"train\"],\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"formattedchat\",\n",
    "    # dataset_text_field=\"text\",\n",
    "    dataset_batch_size=1,\n",
    "    max_seq_length=512,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing=False,\n",
    "    \n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.model.save_pretrained(output_dir)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/32 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0ebd1cff4ea54c338fc1883dc0f876b5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\myper\\.conda\\envs\\ml\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\myper\\.conda\\envs\\ml\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:31, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.866200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.348400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.234800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.303400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.028900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.259500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "f66b1625f6b5f554",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T17:11:38.816079Z",
     "start_time": "2024-08-09T17:10:35.951335Z"
    }
   },
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    ckpt_dir,\n",
    "    low_cpu_mem_usage=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"cpu\",\n",
    "    offload_buffers=False,\n",
    ")\n",
    "model = PeftModel.from_pretrained(base_model, \"F:\\AugustRoboticsLLM\\LoRAAdapter\", device_map=\"cpu\")\n",
    "model = model.merge_and_unload()\n",
    "model.save_pretrained(\"F:\\AugustRoboticsLLM\\ARLLM\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "27c64dd3363246a68d5ca246b1fa7a68"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "c170d830fda25b13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T08:09:22.501223Z",
     "start_time": "2024-08-10T08:08:43.576898Z"
    }
   },
   "source": [
    "generation_config = GenerationConfig.from_pretrained(ckpt_dir)\n",
    "generation_config.max_new_tokens=150\n",
    "generation_config.repetition_penalty = 1.1\n",
    "prompts = [\n",
    "        # For these prompts, the expected answer is the natural continuation of the prompt\n",
    "        \"The Guiding Station is designed for\",\n",
    "    ]\n",
    "model_inputs = tokenizer(prompts, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "output = model.generate(**model_inputs, generation_config=generation_config)\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=False))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>The Guiding Station is designed for use with our Guiding Station Base Plate (sold separately) and allows you to attach your own custom guiding system, such as a string or a laser line, to help guide the router during operation. The station includes two adjustable arms that can be positioned to accommodate various router sizes and styles.\n",
      "Please note that this item requires the purchase of the Guiding Station Base Plate (Part #1013-01). The base plate must be purchased and installed before using the Guiding Station. Contact customer service if you have any questions about compatibility or installation. This product is not intended for use on routers that do not have a flat bottom or sides. Please ensure your router has a suitable surface area for attachment before purchasing. Consult your router's manual for further information\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "af1947c83fc72c0c",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "generation_config = GenerationConfig.from_pretrained(ckpt_dir)\n",
    "generation_config.max_new_tokens=150\n",
    "generation_config.repetition_penalty = 1.1\n",
    "model_inputs = tokenizer(tokenizer.apply_chat_template([\n",
    "    {\n",
    "    \"role\": \"system\", \"content\": \"Your role is an on-site robotics operation engineer who gives technical and practical advice to client who use Lionel robot to draw lines on the ground.\\n\"\n",
    "    \"You belong to August Robotics Ltd. Please do not answer any question not relate to our business, you can simply refuse it by saying no.\\n\"\n",
    "    \"Let's think through this carefully, step by step.\\n\"\n",
    "    \"\"\"As a member of the support team, it is our responsibility to ensure our Lease Clients have a great experience every time they use their Lionel system. It is not uncommon for them to run into issues when operating the robots - some of these issues may be caused by human error, or system error. Being on the support team means you are able to identify the issue and provide advice to solve the issue. Being on support doesn't mean you have to stare at live client deployments all day, but it does mean you need to be attentive to support requests/emails/messages that come through - and reply to these requests as quickly as possible.\n",
    "One of the most difficult things to do while on support is to identify the root cause of a problem. Often, we are helping clients very far away, without being able to see the equipment. In many situations, remote access is our best tool. By using remote access, we can effectively “see” what the client sees - at least on their tablet. We can also perform a deeper analysis on certain issues by viewing the logs. However, remote access, and checking logs is not always the solution, and often we need to consider various factors to solve a problem.\n",
    "1.Identify the problem symptoms: The first step of solving a problem is to identify exactly what the problem is. Often, we will need to ask the client a few questions to get a better understanding, and narrow down the problem area. Some of these questions could include: Is this the first time this issue has occurred? How often does this issue occur? Did the user do anything specific to get the problem to occur? Has the user restarted any equipment?\n",
    "2.Attempt to match the issue to our list of common issues: Once we have asked a few questions, and narrowed down the issue, we should check our table of common troubleshooting steps. Many client issues of the past have been tracked, evaluated and stored in this table. There is no need to try to re-invent a solution if we already have them. \n",
    "3.If the cause of issue is still unknown: If the issue is still not solved, we need to attempt to identify the cause. Sometimes the cause can be separated into hardware or software. But the problems are not always clear. Depending on the problem, we need to determine a possible approach for the solution. Some possible approaches we have are: Asking the user to reboot problematic devices. Using remote access to view the MSP GUI. Using remote access to view the logs of the Map Server/Robot. If for example, their robot's nozzle is blocked, and they aren't sure what to do - it would be silly to use remote access to assist them. In a situation like this, we need to provide steps that deal with the problem at the source, such as checking the bottle connection, checking that the pump is working, replacing the nozzle etc.\n",
    "4.Knowing when to escalate a problem: As a member of support - you are not alone. Ideally, each member of support should be capable of solving 95% of issues clients face. There will always be undiscovered issues or new scenarios. It's important to know when to escalate a problem to the broader support team. Escalate a problem when: No solution has been found within ~15 minutes. None of the steps in the troubleshooting table have worked. You have tried alternative solutions, that have not worked.\n",
    "Things to consider when being on support: Language / tone of our replies: As a company, we have an extremely international team. We speak many different languages - and so do our clients. Most of our clients will be able to communicate in English. Perfect English is not expected from you! For many of us, English is our second or third language. It might be important to make the client aware of this - a quick introductory message will go a long way. For example: “Hi Mr/Ms ****, Thank you for your message, my name is Leo, I am part of the August Robotics team in Shenzhen. I am here to assist you with your issue. Please note - English is not my first language, but I will try my best to communicate clearly.”\n",
    "Additionally, we need to ensure we are as respectful as possible to the client. Many of our clients are not technically skilled, so something that may seem simple to us as engineers might be very difficult to understand for them. We need to exercise patience when trying to get information about a problem from the clients.\n",
    "Quality of our Replies: When we reply to clients about issues they are having, we need to think about the quality of reply we are giving. Short answers may not be a good way of communicating. We should try to provide as much detail as possible - it's sometimes a good idea to pretend the client has never seen the system before. \\n\"\"\"\n",
    "    \n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\", \"content\": \"what is the guiding station?\"\n",
    "    }], tokenize=False), return_tensors=\"pt\").to(\"cuda\")\n",
    "print(model_inputs)\n",
    "output = model.generate(**model_inputs, generation_config=generation_config)\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=False))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T17:26:22.450702Z",
     "start_time": "2024-08-09T17:26:07.766332Z"
    }
   },
   "cell_type": "code",
   "source": "model = AutoModelForCausalLM.from_pretrained(\"F:\\AugustRoboticsLLM\\ARLLM\", quantization_config=bnb_config, device_map=\"auto\")",
   "id": "ce3389383511036e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8dea36d91c95474e86729f1cb0824dbd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "e023b9f7ecd8ed3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T17:13:58.648871Z",
     "start_time": "2024-08-09T17:13:58.512358Z"
    }
   },
   "source": [
    "import gc\n",
    "del model\n",
    "gc.collect()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3719"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f0e59dad73617d9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T15:40:06.171509Z",
     "start_time": "2024-08-06T15:40:06.140995Z"
    }
   },
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "id": "f966435e59825e8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T17:10:05.713049Z",
     "start_time": "2024-08-09T17:10:05.595020Z"
    }
   },
   "source": [
    "gc.collect()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "2dfcd88fcc728a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T14:21:09.340324Z",
     "start_time": "2024-08-09T14:21:09.306319Z"
    }
   },
   "source": "model.unload()",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241m.\u001B[39munload()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4b545d576077b89d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
